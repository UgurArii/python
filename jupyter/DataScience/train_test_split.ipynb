{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b41ef18e-5c6c-47d5-8552-e8edc8f6956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necesssary Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991acb48-0d33-4a2e-8f6c-78ddc58853a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size  (150, 5)\n",
      "Train size (120, 5)\n",
      "Test size (30, 5)\n"
     ]
    }
   ],
   "source": [
    "def get_iris_data():\n",
    "    \"\"\"\n",
    "    Returns Iris dataset\n",
    "    \"\"\"\n",
    "    #Load iris dataset\n",
    "    data = load_iris()\n",
    "    \n",
    "    #Extract the dependend and independent variables\n",
    "    #y is our class label\n",
    "    #x is our instances/records\n",
    "    x = data['data']\n",
    "    y = data['target']\n",
    "    \n",
    "    #For ease we merge them\n",
    "    #column merge\n",
    "    input_dataset = np.column_stack([x, y])\n",
    "    \n",
    "    #Let us shuffle the dataset\n",
    "    #We want records distributed randomly\n",
    "    #between our test and train set\n",
    "    \n",
    "    np.random.shuffle(input_dataset)\n",
    "    \n",
    "    return input_dataset\n",
    "\n",
    "#we need 80/20 split\n",
    "#80% of our records for Training \n",
    "#20% REmaining for our Test set\n",
    "train_size = 0.8\n",
    "test_size = 1 - train_size\n",
    "\n",
    "#get the data\n",
    "input_dataset = get_iris_data()\n",
    "\n",
    "#split the data\n",
    "train, test = train_test_split(input_dataset, test_size=test_size)\n",
    "\n",
    "#Print the size of original dataset\n",
    "print(\"Dataset size \", input_dataset.shape)\n",
    "\n",
    "#Print the train/test split\n",
    "print(\"Train size\", train.shape)\n",
    "print(\"Test size\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ad2fc9-3576-41c2-b1c0-01ab383bd4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data set class label distribution\n",
      "Class label=0, percentage records = 0.33\n",
      "Class label=1, percentage records = 0.33\n",
      "Class label=2, percentage records = 0.33\n",
      "\n",
      "Test data set class label distribution\n",
      "=========================================\n",
      "\n",
      "Class label = 0, percentage records = 0.33\n",
      "Class label = 1, percentage records = 0.33\n",
      "Class label = 2, percentage records = 0.33\n"
     ]
    }
   ],
   "source": [
    "def get_class_distribution(y):\n",
    "    \"\"\"\n",
    "    Given an array of class labels\n",
    "    Return the class distribution\n",
    "    \"\"\"\n",
    "    distribution = {}\n",
    "    set_y = set(y)\n",
    "    for y_label in set_y:\n",
    "        no_elements = len(np.where(y == y)[0])\n",
    "        distribution[y_label] = no_elements\n",
    "    dist_percentage = {class_label: count/(1.0*sum(distribution.values()))\n",
    "                      for class_label, count in distribution.items()}\n",
    "    return dist_percentage\n",
    "\n",
    "def print_class_label_split(train, test):\n",
    "    \"\"\"\n",
    "    Print the class distribution\n",
    "    in test and train dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    y_train = train[:,-1]\n",
    "    train_distribution = get_class_distribution(y_train)\n",
    "    print(\"\\nTrain data set class label distribution\")\n",
    "    for k, v in train_distribution.items():\n",
    "        print(\"Class label=%d, percentage records = %.2f\"%(k, v))\n",
    "    \n",
    "    y_test = test[:,-1]\n",
    "    \n",
    "    test_distribution = get_class_distribution(y_test)\n",
    "    \n",
    "    print(\"\\nTest data set class label distribution\")\n",
    "    print(\"=========================================\\n\")\n",
    "    for k, v in test_distribution.items():\n",
    "        print(\"Class label = %d, percentage records = %.2f\"%(k,v))\n",
    "        \n",
    "print_class_label_split(train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b91a165-acc0-4b5e-aae0-430599007bb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4777/227533026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Let’s see how we distribute the class labels uniformly between the train and the test sets:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Perform Split the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstratified_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_indx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstratified_split\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_iter'"
     ]
    }
   ],
   "source": [
    "#Let’s see how we distribute the class labels uniformly between the train and the test sets:\n",
    "#Perform Split the data\n",
    "stratified_split = StratifiedShuffleSplit(input_dataset[:,-1],test_size=test_size,n_iter=1)\n",
    "\n",
    "for train_indx, test_indx in stratified_split:\n",
    "    train = input_dataset[train_indx]\n",
    "    test = input_dataset[train_indx]\n",
    "    print_class_label_split(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3460fa-873b-4b08-babd-df400dc03e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bff026-9063-4d80-b454-2efd56fd0e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
