{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a83f328-4e82-4001-8d39-d5c45007fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "806074f7-4479-4e0a-aea8-7c9d007bc0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(data, element):\n",
    "    \"\"\"Calculates the percentage count of a given element\n",
    "    Given a list and an element, returns the elements percentage count\n",
    "    \"\"\"\n",
    "    element_count = 0\n",
    "    #test conditoin to check if we have proper input\n",
    "    if len(data) == 0 or element == None or not isinstance(element, (int, long, float)):\n",
    "        return None\n",
    "    element_count = data.count(element)\n",
    "    return element_count / (1.0 * len(data))\n",
    "\n",
    "def entropy(data):\n",
    "    \"\"\"calculate entropy\n",
    "    \"\"\"\n",
    "    entropy = 0.0\n",
    "    if len(data) == 0:\n",
    "        return None\n",
    "    if len(data) == 1:\n",
    "        return 0\n",
    "    try: \n",
    "        for element in data:\n",
    "            p = prob(data, element)\n",
    "            entropy += 1*p*math.log(p,2)\n",
    "    except ValueError as e:\n",
    "         print(e.message)\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe716262-a2ff-4935-8756-a56c83329cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce3c1e27-46a4-433d-8eca-0907fff3f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    Get Iris data\n",
    "    \"\"\"\n",
    "    data = load_iris()\n",
    "    x = data['data']\n",
    "    y = data['target']\n",
    "    label_names = data['target_names']\n",
    "    \n",
    "    return x, y, label_names.tolist()\n",
    "\n",
    "def get_train_test(x, y):\n",
    "    \"\"\"\n",
    "    Prepare a stratified train and test split\n",
    "    \"\"\"\n",
    "    \n",
    "    train_size = 0.0\n",
    "    test_size = 1-train_size\n",
    "    input_dataset = np.column_stack([x, y])\n",
    "    stratified_split = StratifiedShuffleSplit(input_dataset[:,-1], test_size = test_size, n_iter=1, random_state=77)\n",
    "    \n",
    "    for train_indx, test_indx in stratified_split:\n",
    "        train_x = input_dataset[train_indx, : -1]\n",
    "        train_y = input_dataset[train_indx, : -1]\n",
    "        test_x = input_dataset[test_indx, : -1]\n",
    "        test_y = input_dataset[test_indx, -1]\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "#Letâ€™s write the functions to help us build and test the decision tree model:\n",
    "def build_model(x, y):\n",
    "    \"\"\"\n",
    "    Fit the model for the given attribute\n",
    "    class label pairs\n",
    "    \"\"\"\n",
    "    model = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "    model = model.fit(x,y)\n",
    "    return model\n",
    "\n",
    "def test_model(x, y, model, label_names):\n",
    "    \"\"\"\n",
    "    Inspect the model for accuracy\n",
    "    \"\"\"\n",
    "    y_predicted = model.predict(x)\n",
    "    print(\"Model accuracy = %0.2f\"%(accuracy_score(y,y_predicted) * 100) +\n",
    "    \"%\\n\")\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    print(\"=================\")\n",
    "    print(pprint.pprint(confusion_matrix(y,y_predicted)))\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(\"=================\")\n",
    "    print(classification_report(y,y_predicted,target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ae5fa42-5f57-4c18-b89b-55101354f366",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6106/2461237234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#Split the data into train and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Build model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6106/2052991333.py\u001b[0m in \u001b[0;36mget_train_test\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0minput_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mstratified_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m77\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_indx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstratified_split\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_iter'"
     ]
    }
   ],
   "source": [
    "#Finally, the main function to invoke all the other functions that we defined is as follows:\n",
    "if __name__ == \"__main__\":\n",
    "    #Load the data\n",
    "    x, y, label_names = get_data()\n",
    "    \n",
    "    #Split the data into train and test\n",
    "    train_x, train_y, test_x, test_y = get_train_test(x, y)\n",
    "    \n",
    "    #Build model\n",
    "    model = build_model(train_x, train_y)\n",
    "    \n",
    "    #Evaluate the model on train dataset\n",
    "    test_model(train_x, train_y, model, label_names)\n",
    "    \n",
    "    #Evaluate the model on test dataset\n",
    "    test_model(test_x, test_y, model, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea201f3-70e6-4282-a95c-2b6559a2c969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
