{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b810dd68-9416-4be5-a488-f882cd427062",
   "metadata": {},
   "source": [
    "Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4187e6b7-d6ed-4f16-a739-7eb4c4ec6adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c9932d-8402-40fa-9dcb-1bd87b9acdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Downloader>  L\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Packages:\n",
      "  [ ] abc................. Australian Broadcasting Commission 2006\n",
      "  [ ] alpino.............. Alpino Dutch Treebank\n",
      "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
      "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
      "  [ ] basque_grammars..... Grammars for Basque\n",
      "  [ ] bcp47............... BCP-47 Language Tags\n",
      "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
      "                           Extraction Systems in Biology)\n",
      "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
      "  [ ] book_grammars....... Grammars from NLTK Book\n",
      "  [ ] brown............... Brown Corpus\n",
      "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
      "  [ ] cess_cat............ CESS-CAT Treebank\n",
      "  [ ] cess_esp............ CESS-ESP Treebank\n",
      "  [ ] chat80.............. Chat-80 Data Files\n",
      "  [ ] city_database....... City Database\n",
      "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
      "  [ ] comparative_sentences Comparative Sentence Dataset\n",
      "  [ ] comtrans............ ComTrans Corpus Sample\n",
      "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hit Enter to continue:  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
      "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
      "                           and Basque Subset)\n",
      "  [ ] crubadan............ Crubadan Corpus\n",
      "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
      "  [ ] dolch............... Dolch Word List\n",
      "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
      "                           Corpus\n",
      "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
      "  [ ] floresta............ Portuguese Treebank\n",
      "  [ ] framenet_v15........ FrameNet 1.5\n",
      "  [ ] framenet_v17........ FrameNet 1.7\n",
      "  [ ] gazetteers.......... Gazeteer Lists\n",
      "  [ ] genesis............. Genesis Corpus\n",
      "  [ ] gutenberg........... Project Gutenberg Selections\n",
      "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
      "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
      "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
      "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
      "                           ChaSen format)\n",
      "  [ ] kimmo............... PC-KIMMO Data Files\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_shell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tutorial-env/lib/python3.10/site-packages/nltk/downloader.py:2484\u001b[0m, in \u001b[0;36mdownload_shell\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_shell\u001b[39m():\n\u001b[0;32m-> 2484\u001b[0m     \u001b[43mDownloaderShell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_downloader\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tutorial-env/lib/python3.10/site-packages/nltk/downloader.py:1150\u001b[0m, in \u001b[0;36mDownloaderShell.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m command \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m-> 1150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmore_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m command \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simple_interactive_help()\n",
      "File \u001b[0;32m~/tutorial-env/lib/python3.10/site-packages/nltk/downloader.py:569\u001b[0m, in \u001b[0;36mDownloader.list\u001b[0;34m(self, download_dir, show_packages, show_collections, header, more_prompt, skip_installed)\u001b[0m\n\u001b[1;32m    567\u001b[0m lines \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# for more_prompt\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m more_prompt \u001b[38;5;129;01mand\u001b[39;00m lines \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m20\u001b[39m:\n\u001b[0;32m--> 569\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHit Enter to continue: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    571\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/tutorial-env/lib/python3.10/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tutorial-env/lib/python3.10/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d922a3-81e2-4021-9d97-bf7f24479775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Downloader>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download which package (l=list; x=cancel)?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Identifier>  gb = nltk.corpus.gutenberg print (\"Gutenberg files:\", gb.fileids ())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Error loading gb: Package 'gb' not found in index\n",
      "    Error loading =: Package '=' not found in index\n",
      "    Error loading nltk.corpus.gutenberg: Package\n",
      "        'nltk.corpus.gutenberg' not found in index\n",
      "    Error loading print: Package 'print' not found in index\n",
      "    Error loading (\"Gutenberg: Package '(\"Gutenberg' not found in\n",
      "        index\n",
      "    Error loading files:\",: Package 'files:\",' not found in index\n",
      "    Error loading gb.fileids: Package 'gb.fileids' not found in index\n",
      "    Error loading ()): Package '())' not found in index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Downloader>  gb = nltk.corpus.gutenberg print (\"Gutenberg files:\", gb.fileids ())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command 'gb = nltk.corpus.gutenberg print (\"Gutenberg files:\", gb.fileids ())' unrecognized\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Downloader>  Gutenberg files :  ['austen-emma.txt', 'austen-persuasion.txt', 'austen-­ sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command \"Gutenberg files :  ['austen-emma.txt', 'austen-persuasion.txt', 'austen-\\xad sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\" unrecognized\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Downloader>  len(macbeth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command 'len(macbeth)' unrecognized\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Downloader>  q\n"
     ]
    }
   ],
   "source": [
    "nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb158a4f-87c1-4324-81c6-e477af8a1f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506860db-ec54-44f7-827b-f1c3f80fb60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gutenberg files: ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "gb = nltk.corpus.gutenberg\n",
    "print (\"Gutenberg files:\", gb.fileids ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e01f34-11fc-459c-b382-ea48eab2a9cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (785317868.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Gutenberg files :  ['austen-emma.txt', 'austen-persuasion.txt', 'austen-­\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "Gutenberg files :  ['austen-emma.txt', 'austen-persuasion.txt', 'austen-­\n",
    "sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt',\n",
    "'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt',\n",
    "'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt',\n",
    "'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt',\n",
    "'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
    "len(macbeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e2b94-ae46-4a4b-a199-49f2211326fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth [:10]\n",
    "['[',\n",
    "'The',\n",
    "'Tragedie',\n",
    "'of',\n",
    "'Macbeth',\n",
    "'by',\n",
    "'William',\n",
    "'Shakespeare',\n",
    "'1603',\n",
    "']']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac74eb-728b-4c49-8222-232ecf1db4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_sents = nltk.corpus.gutenberg.sents ('shakespeare-macbeth.txt')\n",
    "macbeth_sents [: 5]\n",
    "[['[',\n",
    "  'The',\n",
    "  'Tragedie',\n",
    "  'of',\n",
    "  'Macbeth',\n",
    "  'by',\n",
    "  'William',\n",
    "  'Shakespeare',\n",
    "  '1603',\n",
    "  ']'],\n",
    "['Actus', 'Primus', '.'],\n",
    "['Scoena', 'Prima', '.'],\n",
    "['Thunder', 'and', 'Lightning', '.'],\n",
    "['Enter', 'three', 'Witches', '.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9ee19-25d4-4fe3-ab0a-c797eb2da668",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(macbeth)\n",
    "text.concordance('Stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7b0ca-403a-4317-af6c-f325bd277a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.common_contexts(['Stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c8caa2-c561-4997-9232-c5e51d50ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(macbeth)\n",
    "fd.most_common(10)\n",
    "[(',', 1962),\n",
    "('.', 1235),\n",
    "(\"'\", 637),\n",
    "('the', 531),\n",
    "(':', 477),\n",
    "('and', 376),\n",
    "('I', 333),\n",
    "('of', 315),\n",
    "('to', 311),\n",
    "('?', 241)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8ad7e-b849-4115-a543-a999473ddc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e27fae-4041-449c-89e3-99393b7be07e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'macbeth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m macbeth_filtered \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmacbeth\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sw]\n\u001b[1;32m      2\u001b[0m fd \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mFreqDist (macbeth_filtered)\n\u001b[1;32m      3\u001b[0m fd\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'macbeth' is not defined"
     ]
    }
   ],
   "source": [
    "macbeth_filtered = [w for w in macbeth if w.lower() not in sw]\n",
    "fd = nltk.FreqDist (macbeth_filtered)\n",
    "fd.most_common(10)\n",
    "[(',', 1962),\n",
    "('.', 1235),\n",
    "(\"'\", 637),\n",
    "(':', 477),\n",
    "('?', 241),\n",
    "('Macb', 137),\n",
    "('haue', 117),\n",
    "('-', 100),\n",
    "('Enter', 80),\n",
    "('thou', 63)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ddc726-4f31-450e-846c-72de37f690db",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2540350318.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    Now you can recalculate the frequency distribution of words.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuation = set (string.punctuation)\n",
    "macbeth_filtered2 = [w.lower () for w in macbeth if w.lower () not in sw\n",
    "and w.lower () not in punctuation]\n",
    "Now you can recalculate the frequency distribution of words.\n",
    "fd = nltk.FreqDist (macbeth_filtered2)\n",
    "fd.most_common(10)\n",
    "[('macb', 137),\n",
    "('haue', 122),\n",
    "('thou', 90),\n",
    "('enter', 81),\n",
    "('shall', 68),\n",
    "('macbeth', 62),\n",
    "('vpon', 62),\n",
    "('thee', 61),\n",
    "('macd', 58),\n",
    "('vs', 57)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11cc445-4200-4e79-b4a7-d5b9a840d72e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'long_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28msorted\u001b[39m(\u001b[43mlong_words\u001b[49m)\n\u001b[1;32m      2\u001b[0m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssassination\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChamberlaines\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistinguishes\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupernaturall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvnaccompanied\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'long_words' is not defined"
     ]
    }
   ],
   "source": [
    "sorted(long_words)\n",
    "['Assassination',\n",
    "'Chamberlaines',\n",
    "'Distinguishes',\n",
    "'Gallowgrosses',\n",
    "'Metaphysicall',\n",
    "'Northumberland',\n",
    "'Voluptuousnesse',\n",
    "'commendations',\n",
    "'multitudinous',\n",
    "'supernaturall',\n",
    "'vnaccompanied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f07626-4301-4f93-b381-486ae0d1089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious_words = [w for w in macbeth if 'ious' in w]\n",
    "ious_words = set(ious_words)\n",
    "sorted(ious_words)\n",
    "['Auaricious',\n",
    "'Gracious',\n",
    "'Industrious',\n",
    "'Iudicious',\n",
    " 'Luxurious',\n",
    "'Malicious',\n",
    "'Obliuious',\n",
    "'Pious',\n",
    "'Rebellious',\n",
    "'compunctious',\n",
    "'furious',\n",
    "'gracious',\n",
    "'pernicious',\n",
    "'pernitious',\n",
    "'pious',\n",
    "'precious',\n",
    "'rebellious',\n",
    "'sacrilegious',\n",
    "'serious',\n",
    "'spacious',\n",
    "'tedious']\n",
    " bgrms = nltk.FreqDist(nltk.bigrams(macbeth_filtered2))\n",
    "bgrms.most_common(15)\n",
    "[(('enter', 'macbeth'), 16),\n",
    "(('exeunt', 'scena'), 15),\n",
    "(('thane', 'cawdor'), 13),\n",
    "(('knock', 'knock'), 10),\n",
    "(('st', 'thou'), 9),\n",
    "(('thou', 'art'), 9),\n",
    "(('lord', 'macb'), 9),\n",
    "(('haue', 'done'), 8),\n",
    "(('macb', 'haue'), 8),\n",
    "(('good', 'lord'), 8),\n",
    "(('let', 'vs'), 7),\n",
    "(('enter', 'lady'), 7),\n",
    "(('wee', 'l'), 7),\n",
    "(('would', 'st'), 6),\n",
    "(('macbeth', 'macb'), 6)]\n",
    "tgrms = nltk.FreqDist(nltk.trigrams (macbeth_filtered2))\n",
    "tgrms.most_common(10)\n",
    "[(('knock', 'knock', 'knock'), 6),\n",
    "(('enter', 'macbeth', 'macb'), 5),\n",
    "(('enter', 'three', 'witches'), 4),\n",
    "(('exeunt', 'scena', 'secunda'), 4),\n",
    "(('good', 'lord', 'macb'), 4),\n",
    "(('three', 'witches', '1'), 3),\n",
    "(('exeunt', 'scena', 'tertia'), 3),\n",
    "(('thunder', 'enter', 'three'), 3),\n",
    "(('exeunt', 'scena', 'quarta'), 3),\n",
    "(('scena', 'prima', 'enter'), 3)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
